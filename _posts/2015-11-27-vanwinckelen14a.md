---
title: 'Look before you leap: Some insights into learner evaluation with cross-validation'
abstract: 'Machine learning is largely an experimental science, of which the evaluation
  of predictive models is an important aspect. These days, cross-validation is the
  most widely used method for this task. There are, however, a number of important
  points that should be taken into account when using this methodology. First, one
  should clearly state what they are trying to estimate. Namely, a distinction should
  be made between the evaluation of a model learned on a single dataset, and that
  of a learner trained on a random sample from a given data population. Each of these
  two questions requires a different statistical approach and should not be confused
  with each other. While this has been noted before, the literature on this topic
  is generally not very accessible. This paper tries to give an understandable overview
  of the statistical aspects of these two evaluation tasks. We also pose that because
  of the often limited availability of data, and the difficulty of selecting an appropriate
  statistical test, it is in some cases perhaps better to abstain from statistical
  testing, and instead focus on an interpretation of the immediate results. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: vanwinckelen14a
month: 0
firstpage: 3
lastpage: 20
page: 3-20
sections: 
author:
- given: Gitte
  family: Vanwinckelen
- given: Hendrik
  family: Blockeel
date: 2015-11-27
address: Nancy, France
publisher: PMLR
container-title: Proceedings of the Workshop on Statistically Sound Data Mining at
  ECML/PKDD
volume: '47'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 11
  - 27
pdf: http://proceedings.mlr.press/v47/vanwinckelen14a/vanwinckelen14a.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
